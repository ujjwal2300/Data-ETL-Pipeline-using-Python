{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uofzYSLr49Rg",
        "outputId": "9ca20b53-0c56-44ec-8df2-1951b7734b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as keras\n",
        "(xtrain, ytrain), (xtest, ytest) = keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtrain.shape)\n",
        "print(ytrain.shape)\n",
        "print(xtest.shape)\n",
        "print(ytest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXo1Yx9q5Fh3",
        "outputId": "9454b421-9f34-439a-e0eb-2cdd6144825b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s clean and transform the data. Here we will normalize the pixel values to be between 0 and 1 and reshape the data into a 4D tensor:"
      ],
      "metadata": {
        "id": "F5Cohxtq6dKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "xtrain = xtrain.astype('float32') / 255\n",
        "xtest = xtest.astype('float32') / 255\n",
        "\n",
        "xtrain = np.reshape(xtrain, (xtrain.shape[0], 28, 28, 1))\n",
        "xtest = np.reshape(xtest, (xtest.shape[0], 28, 28, 1))\n",
        "\n",
        "print(xtrain.shape)\n",
        "print(ytrain.shape)\n",
        "print(xtest.shape)\n",
        "print(ytest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxdH7DDi5Eeb",
        "outputId": "7a12eb5b-fe2d-445a-a8d7-0da6052d33df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E2LEZkuZ6nv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s load the data into a database. We can use SQLite to create a database and load the data into it:"
      ],
      "metadata": {
        "id": "-chnKyMZ60Vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('fashion_mnist.db')\n",
        "\n",
        "conn.execute('''CREATE TABLE IF NOT EXISTS images\n",
        "             (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "             image BLOB NOT NULL,\n",
        "             label INTEGER NOT NULL);''')\n",
        "\n",
        "for i in range(xtrain.shape[0]):\n",
        "    conn.execute('INSERT INTO images (image, label) VALUES (?, ?)',\n",
        "                [sqlite3.Binary(xtrain[i]), ytrain[i]])\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "for i in range(xtest.shape[0]):\n",
        "    conn.execute('INSERT INTO images (image, label) VALUES (?, ?)',\n",
        "                [sqlite3.Binary(xtest[i]), ytest[i]])\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "x2hsEZhh61R2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4nppBhOv9W-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So this is how we can create a Data ETL pipeline using Python. Our ETL pipeline takes the Fashion MNIST dataset and stores it in an SQLite database so that we can easily access and manipulate the data later."
      ],
      "metadata": {
        "id": "NRHv6fWS-ZLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "conn = sqlite3.connect('fashion_mnist.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute('SELECT * FROM images')\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_sql_query('SELECT * FROM images', conn)"
      ],
      "metadata": {
        "id": "XtaNFQxH-aBy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YEQ6a2DQ-gVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}